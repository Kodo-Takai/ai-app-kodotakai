# üì± Gu√≠a de Integraci√≥n M√≥vil - IA Tur√≠stica Sincelejo y Sucre

## üéØ Resumen del Proyecto

Este proyecto implementa un sistema de IA local para una aplicaci√≥n tur√≠stica de Sincelejo y Sucre, Colombia, que funciona completamente offline en dispositivos m√≥viles.

## üèóÔ∏è Arquitectura de Modelos

### Modelos por Requerimiento Funcional

| RF | Funcionalidad | Modelo | Tama√±o | Plataforma |
|---|---|---|---|---|
| **RF-04** | Recomendaciones personalizadas | LightFM + AutoMLP | 50MB | Android/iOS |
| **RF-05** | Planificaci√≥n temporal | Prophet + LSTM | 30MB | Cross-platform |
| **RF-10** | Notificaciones personalizadas | DistilBERT | 63MB | ONNX Runtime |
| **RF-18** | Optimizaci√≥n de rutas | GraphSAGE + A* | 20MB | Native |
| **RF-19** | Segmentaci√≥n de usuario | K-Means + Autoencoder | 15MB | TensorFlow Lite |
| **RF-20** | Res√∫menes autom√°ticos | DistilBART | 300MB | ONNX Runtime |
| **RF-28** | Chat conversacional | Phi-3-mini (4B) | 625MB | ONNX Runtime |

## üöÄ Pipeline de Implementaci√≥n

### 1. Configuraci√≥n Inicial
```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar entorno
python setup_environment.py
```

### 2. Descarga de Modelos
```bash
# Descargar modelos base
python download_models.py
```

### 3. Entrenamiento Local
```bash
# Entrenar con datos de Sincelejo y Sucre
python train_local.py
```

### 4. Optimizaci√≥n para M√≥viles
```bash
# Optimizar modelos para dispositivos m√≥viles
python optimize_models.py
```

## üìä Estrategias de Optimizaci√≥n

### Cuantizaci√≥n
- **DistilBERT**: 250MB ‚Üí 63MB (75% reducci√≥n)
- **Phi-3-mini**: 2.5GB ‚Üí 625MB (75% reducci√≥n)
- **T√©cnica**: INT8 quantization con TensorFlow Lite y ONNX Runtime

### Pruning
- Eliminaci√≥n de conexiones menos importantes
- Reducci√≥n de par√°metros sin p√©rdida significativa de precisi√≥n
- Aplicado a modelos de recomendaci√≥n y clasificaci√≥n

### Knowledge Distillation
- Modelos grandes (maestro) ‚Üí Modelos peque√±os (estudiante)
- Mantiene rendimiento con menor tama√±o
- Especialmente √∫til para modelos de chat

## üì± Integraci√≥n M√≥vil

### Android (TensorFlow Lite)
```kotlin
// Ejemplo de integraci√≥n en Android
class RecommendationEngine {
    private var interpreter: Interpreter? = null
    
    fun loadModel(context: Context) {
        val modelFile = loadModelFile(context, "recommendation_model.tflite")
        interpreter = Interpreter(modelFile)
    }
    
    fun getRecommendations(userFeatures: FloatArray): List<Activity> {
        val input = arrayOf(userFeatures)
        val output = Array(1) { FloatArray(10) }
        interpreter?.run(input, output)
        return processOutput(output[0])
    }
}
```

### iOS (ONNX Runtime)
```swift
// Ejemplo de integraci√≥n en iOS
class ChatBot {
    private var session: ORTSession?
    
    func loadModel() {
        guard let modelPath = Bundle.main.path(forResource: "phi3_mini_mobile", ofType: "onnx") else { return }
        session = try? ORTSession(modelPath: modelPath)
    }
    
    func generateResponse(prompt: String) -> String {
        let input = prepareInput(prompt)
        let output = try? session?.run(withInputs: input, outputNames: ["logits"])
        return processOutput(output)
    }
}
```

## üéØ Modelos Recomendados para Empezar

### 1. DistilBERT (250MB ‚Üí 63MB)
- **Uso**: Clasificaci√≥n de notificaciones, procesamiento de texto
- **Descarga**: `python download_models.py`
- **Optimizaci√≥n**: Cuantizaci√≥n INT8 autom√°tica

### 2. LightFM (50MB)
- **Uso**: Sistema de recomendaciones
- **Ventaja**: Ligero y eficiente
- **Entrenamiento**: Con datos locales de Sincelejo y Sucre

### 3. Sentence Transformer (80MB)
- **Uso**: Embeddings para similitud de actividades
- **Aplicaci√≥n**: B√∫squeda sem√°ntica de actividades tur√≠sticas

### 4. Phi-3-mini (2.5GB ‚Üí 625MB)
- **Uso**: Chat conversacional
- **Optimizaci√≥n**: Cuantizaci√≥n + ONNX
- **Recomendaci√≥n**: Usar solo si es esencial

## üìà M√©tricas de Rendimiento

### Tiempo de Inferencia
- **DistilBERT**: ~50ms en smartphone promedio
- **LightFM**: ~10ms para recomendaciones
- **Phi-3-mini**: ~200ms para respuestas de chat

### Uso de Memoria
- **RAM**: 100-200MB total
- **Almacenamiento**: 1-2GB para todos los modelos
- **Bater√≠a**: Impacto m√≠nimo con optimizaciones

## üîß Herramientas de Desarrollo

### Frameworks
- **TensorFlow Lite**: Para Android
- **ONNX Runtime Mobile**: Para iOS y cross-platform
- **Core ML**: Alternativa para iOS

### Librer√≠as Python
- **Optimum**: Optimizaci√≥n de modelos Hugging Face
- **Neural Compressor**: Cuantizaci√≥n avanzada
- **LightFM**: Sistemas de recomendaci√≥n

## üìã Checklist de Implementaci√≥n

### Fase 1: Preparaci√≥n
- [ ] Instalar dependencias
- [ ] Configurar entorno
- [ ] Descargar modelos base

### Fase 2: Entrenamiento
- [ ] Recopilar datos locales
- [ ] Entrenar modelos
- [ ] Validar rendimiento

### Fase 3: Optimizaci√≥n
- [ ] Aplicar cuantizaci√≥n
- [ ] Optimizar para m√≥viles
- [ ] Probar en dispositivos reales

### Fase 4: Integraci√≥n
- [ ] Integrar en app Android
- [ ] Integrar en app iOS
- [ ] Pruebas de rendimiento

## üéØ Pr√≥ximos Pasos Recomendados

1. **Empezar con DistilBERT** (m√°s peque√±o, f√°cil de probar)
2. **Implementar LightFM** para recomendaciones b√°sicas
3. **Probar en dispositivo m√≥vil** antes de modelos m√°s grandes
4. **Recopilar datos reales** de usuarios de Sincelejo y Sucre
5. **Iterar y mejorar** basado en feedback real

## üìû Soporte y Recursos

- **Documentaci√≥n TensorFlow Lite**: https://www.tensorflow.org/lite
- **ONNX Runtime Mobile**: https://onnxruntime.ai/docs/build/eps.html
- **Hugging Face Models**: https://huggingface.co/models
- **LightFM Documentation**: https://github.com/lyst/lightfm

---

*Desarrollado para el proyecto tur√≠stico de Sincelejo y Sucre, Colombia*

